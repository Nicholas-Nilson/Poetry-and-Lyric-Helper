{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e8cdc1",
   "metadata": {},
   "source": [
    "Markdown cells are for personal notes & thought process. This notebook in general is for a more interactive experience as I work through setting up the database for this helper tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21e082da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770dc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wordnet20-from-prolog-all-3.sql',\n",
       " 'Untitled.ipynb',\n",
       " 'cmudict-0.7b.phones',\n",
       " 'cmudict-0.7b',\n",
       " 'newdic.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'cmudict-pared.txt',\n",
       " 'cmudict-0.7b.symbols']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d2000",
   "metadata": {},
   "source": [
    "## Initial data import\n",
    "file - 'cmu-dict-test.txt', temporary project file with a much smaller overall list of words\n",
    "\n",
    "issues: \n",
    "-parse the two columns to a dataframe, pronunciations are separated by white space, each word is separated by a new line.\n",
    "-supply column names\n",
    "\n",
    "word -> first white space -> turn pronunciations in to list\n",
    "    -i.e. HH A0 R D L YY1 ['HH', 'A0', 'R', 'D', 'L', 'YY1']\n",
    "    -then look for \\n for next entry in dataframe\n",
    "    -to do this, we can make an initial list by removing all whitespace, index 0 is the word. the rest will be the phonemes.\n",
    "    \n",
    "potential steps:\n",
    "- make a list of each word, then each pronunciation\n",
    "- after this, I have my basis for the initial dataframe\n",
    "- then I can write functions to parse each pronunciation for syllable count & stressed, and create a list for each of those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b448487",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = open('cmudict-pared.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "# utf-8 was not the default encoding for this file. \n",
    "# something to keep note of in case this affects searching results\n",
    "# later in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dddd0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary.readline()\n",
    "# imported correctly, now to make initial list, per line in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd13af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word in the CMUdict is separated by a new line.\n",
    "# want to split and get rid of \\n character\n",
    "\n",
    "entries = [word.rstrip('\\n') for word in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76a24876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABBENHAUS  AE1 B AH0 N HH AW2 S'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking random entries\n",
    "\n",
    "entries[101]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d87f3b",
   "metadata": {},
   "source": [
    "### splitting each entry to a word & phonics\n",
    "\n",
    "- must first split each by white space and then pull index 0 from each of those splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc8c546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'ALLO\", '', 'AA2', 'L', 'OW1']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_word = entries[0].split(' ')\n",
    "sample_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28ed2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up where they'll go, and we can probably separate the word\n",
    "# & pronunciation lists in one pass while using the split method.\n",
    "words = []\n",
    "pronunciations = []\n",
    "\n",
    "for item in entries:\n",
    "    item = item.split(' ')\n",
    "    words.append(item[0])\n",
    "    pronunciations.append(item[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c10110d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134323"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddbe3d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134323"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pronunciations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24f42446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'ROUND\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09d9749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'AA2', 'HH', 'UW1', 'S']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f636a",
   "metadata": {},
   "source": [
    "* something to keep track of is the pronunciation in list format. When searching for rhymes, would it be more efficient to have this in list form or string form? It would be a matter of comparing substrings and delimited white space vs number of indexes in common at the end of each list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be454e7",
   "metadata": {},
   "source": [
    "## getting syllable counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e1eca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "numbers = r'\\d'\n",
    "\n",
    "# count = sum(numbers in item for item in pronunciations[13])\n",
    "# count\n",
    "\n",
    "# this is a potential setup for what I need to do for syllable counts\n",
    "# a list comprehension with something like the below could get me syllable\n",
    "# counts for each word.\n",
    "\n",
    "for item in pronunciations[45]:\n",
    "    if bool(re.search(numbers, item)):\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "067659f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(list):\n",
    "    count = 0\n",
    "    for item in list:\n",
    "        if bool(re.search(numbers, item)):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8bee3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = [count_syllables(x) for x in pronunciations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2d995c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134323"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syllables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0585c085",
   "metadata": {},
   "source": [
    "^ looks like we got the whole list\n",
    "\n",
    "\\\\/ some checks for various syllable counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11de97fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd8c234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables[197]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "008e027b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.index('ABERRATIONAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d122cae",
   "metadata": {},
   "source": [
    "Looking good, now to parse meter from each of these entries.\n",
    "\n",
    "## Syllable stresses\n",
    "\n",
    "The numbers attached to vowel sounds indicate stresses;\n",
    "- 0: no stress\n",
    "- 1: primary stress\n",
    "- 2: secondary stress\n",
    "\n",
    "### How to handle stresses?\n",
    "- secondary stresses have a weird place in this project. \n",
    "- I could decide to count them as stresses always, but that doesn't tell the whole story of secondary stresses.\n",
    "- There are cases where secondary stresses get promoted to a primary stress depending on surrounding syllables and/or meter.\n",
    "- For the set-up of my database, more research on how to handle these will need to be.\n",
    "- In the end it will modify how some functions are written and certainly how lines are parsed for meter when that feature is added.\n",
    "\n",
    "Will need to look at the necessity of separating primary & secondary stress vs combining them... '\\`_\n",
    "\n",
    "... So why make all these lists and not just run the functions each time a word is searched?\n",
    "    - It'll be better to search the database pre-filled later than run functions over the entire dictionary later.\n",
    "    - The database may need further fields, or bins of some kind for feet/meter & rhymes. Those will require searching the entire dicitonary.\n",
    "    - English has 44 phonemes. These pronunciations can be grouped by phonemes. ??? searching end-rhymes vs full/partial word-rhymes???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a72b264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
