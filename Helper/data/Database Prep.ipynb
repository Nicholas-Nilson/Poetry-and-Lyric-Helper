{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e8cdc1",
   "metadata": {},
   "source": [
    "Markdown cells are for personal notes & thought process. This notebook in general is for a more interactive experience as I work through setting up the database for this helper tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e082da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770dc986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wordnet20-from-prolog-all-3.sql',\n",
       " 'cmudict-0.7b.phones',\n",
       " 'cmudict-0.7b',\n",
       " 'newdic.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'cmudict-pared.txt',\n",
       " 'cmudict-0.7b.symbols',\n",
       " 'cmu-dict-test.txt',\n",
       " 'Database Prep.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d2000",
   "metadata": {},
   "source": [
    "## Initial data import\n",
    "file - 'cmu-dict-test.txt', temporary project file with a much smaller overall list of words\n",
    "\n",
    "issues: \n",
    "-parse the two columns to a dataframe, pronunciations are separated by white space, each word is separated by a new line.\n",
    "-supply column names\n",
    "\n",
    "word -> first white space -> turn pronunciations in to list\n",
    "    -i.e. HH A0 R D L YY1 ['HH', 'A0', 'R', 'D', 'L', 'YY1']\n",
    "    -then look for \\n for next entry in dataframe\n",
    "    -to do this, we can make an initial list by removing all whitespace, index 0 is the word. the rest will be the phonemes.\n",
    "    \n",
    "potential steps:\n",
    "- make a list of each word, then each pronunciation\n",
    "- after this, I have my basis for the initial dataframe\n",
    "- then I can write functions to parse each pronunciation for syllable count & stressed, and create a list for each of those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b448487",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = open('cmudict-pared.txt', 'r', encoding=\"ISO-8859-1\")\n",
    "# utf-8 was not the default encoding for this file. \n",
    "# something to keep note of in case this affects searching results\n",
    "# later in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dddd0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary.readline()\n",
    "# imported correctly, now to make initial list, per line in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd13af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each word in the CMUdict is separated by a new line.\n",
    "# want to split and get rid of \\n character\n",
    "\n",
    "entries = [word.rstrip('\\n') for word in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76a24876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABBEVILLE  AE1 B V IH0 L'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking random entries\n",
    "\n",
    "entries[101]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d87f3b",
   "metadata": {},
   "source": [
    "### splitting each entry to a word & phonics\n",
    "\n",
    "- must first split each by white space and then pull index 0 from each of those splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc8c546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'ALLO\", '', 'AA2', 'L', 'OW1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_word = entries[0].split(' ')\n",
    "sample_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "28ed2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up where they'll go, and we can probably separate the word\n",
    "# & pronunciation lists in one pass while using the split method.\n",
    "words = []\n",
    "pronunciations = []\n",
    "\n",
    "for item in entries:\n",
    "    item = item.split()\n",
    "    words.append(item[0])\n",
    "    pronunciations.append(tuple(item[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c10110d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134316"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ddbe3d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134316"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pronunciations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "680d1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AH0', 'B', 'AH1', 'V', 'Z')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations[313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "77b3c3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134316"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pronunciations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24f42446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'TIL\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "09d9749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('EH1', 'R', 'AH0', 'N', 'Z')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronunciations[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f636a",
   "metadata": {},
   "source": [
    "* something to keep track of is the pronunciation in list format. When searching for rhymes, would it be more efficient to have this in list form or string form? It would be a matter of comparing substrings and delimited white space vs number of indexes in common at the end of each list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be454e7",
   "metadata": {},
   "source": [
    "## getting syllable counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2e1eca94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "numbers = r'\\d'\n",
    "\n",
    "# count = sum(numbers in item for item in pronunciations[13])\n",
    "# count\n",
    "\n",
    "# this is a potential setup for what I need to do for syllable counts\n",
    "# a list comprehension with something like the below could get me syllable\n",
    "# counts for each word.\n",
    "\n",
    "for item in pronunciations[45]:\n",
    "    if bool(re.search(numbers, item)):\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "067659f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(list):\n",
    "    count = 0\n",
    "    for item in list:\n",
    "        if bool(re.search(numbers, item)):\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8bee3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = [count_syllables(x) for x in pronunciations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b2d995c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134316"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syllables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0585c085",
   "metadata": {},
   "source": [
    "^ looks like we got the whole list\n",
    "\n",
    "\\\\/ some checks for various syllable counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "11de97fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dd8c234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables[197]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "008e027b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.index('ABERRATIONAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d122cae",
   "metadata": {},
   "source": [
    "Looking good, now to parse meter from each of these entries.\n",
    "\n",
    "## Syllable stresses\n",
    "\n",
    "The numbers attached to vowel sounds indicate stresses;\n",
    "- 0: no stress\n",
    "- 1: primary stress\n",
    "- 2: secondary stress\n",
    "\n",
    "### How to handle stresses?\n",
    "- secondary stresses have a weird place in this project. \n",
    "- I could decide to count them as stresses always, but that doesn't tell the whole story of secondary stresses.\n",
    "- There are cases where secondary stresses get promoted to a primary stress depending on surrounding syllables and/or meter.\n",
    "- For the set-up of my database, more research on how to handle these will need to be.\n",
    "- In the end it will modify how some functions are written and certainly how lines are parsed for meter when that feature is added.\n",
    "\n",
    "Will need to look at the necessity of separating primary & secondary stress vs combining them... '\\`_\n",
    "\n",
    "... So why make all these lists and not just run the functions each time a word is searched?\n",
    "    - It'll be better to search the database pre-filled later than run functions over the entire dictionary later.\n",
    "    - The database may need further fields, or bins of some kind for feet/meter & rhymes. Those will require searching the entire dicitonary.\n",
    "    - English has 44 phonemes. These pronunciations can be grouped by phonemes. ??? searching end-rhymes vs full/partial word-rhymes???\n",
    "    \n",
    "### Stresses\n",
    "- primary & secondary stresses will be retained\n",
    "- symbols:\n",
    "    - unstressed: _\n",
    "    - primary:    '\n",
    "    - secondary:  \\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5a72b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scansion(list):\n",
    "    scansion = ''\n",
    "    for item in list:\n",
    "        if '0' in item:\n",
    "            scansion += '_'\n",
    "        if '1' in item:\n",
    "            scansion += \"'\"\n",
    "        if '2' in item:\n",
    "            scansion += '`'\n",
    "    return scansion        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "746c22de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134316\n"
     ]
    }
   ],
   "source": [
    "scansion = [parse_scansion(x) for x in pronunciations]\n",
    "print(len(scansion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4a2feb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"`_'__\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scansion[195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "89bbaee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AH0 B AH1 V Z'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing the pronunciations as a list makes it harder to put in to an SQL database. For now \n",
    "# they can be stored as strings. Finding matching rhymes down the road will only slightly change.\n",
    "\n",
    "pronunciations = [' '.join(item) for item in pronunciations]\n",
    "pronunciations[313]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a752d0ab",
   "metadata": {},
   "source": [
    "## time to set up the DataFrame\n",
    "\n",
    "this will eventually be converted to an SQL/postgres database for use in the web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1248b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"WORD\", \"PRONUNCIATION\", \"SYLLABLES\", \"SCANSION\"]\n",
    "l = [list(word) for word in zip(words, pronunciations, syllables, scansion)]\n",
    "df = pd.DataFrame(l, columns= columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5c3c855f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD</th>\n",
       "      <th>PRONUNCIATION</th>\n",
       "      <th>SYLLABLES</th>\n",
       "      <th>SCANSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'ALLO</td>\n",
       "      <td>AA2 L OW1</td>\n",
       "      <td>2</td>\n",
       "      <td>`'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'BOUT</td>\n",
       "      <td>B AW1 T</td>\n",
       "      <td>1</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'CAUSE</td>\n",
       "      <td>K AH0 Z</td>\n",
       "      <td>1</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'COURSE</td>\n",
       "      <td>K AO1 R S</td>\n",
       "      <td>1</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'CUSE</td>\n",
       "      <td>K Y UW1 Z</td>\n",
       "      <td>1</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WORD PRONUNCIATION  SYLLABLES SCANSION\n",
       "0    'ALLO     AA2 L OW1          2       `'\n",
       "1    'BOUT       B AW1 T          1        '\n",
       "2   'CAUSE       K AH0 Z          1        _\n",
       "3  'COURSE     K AO1 R S          1        '\n",
       "4    'CUSE     K Y UW1 Z          1        '"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e10417",
   "metadata": {},
   "source": [
    "necessary columns in place. Time to ponder what else could be useful for the remainder of the project.\n",
    "\n",
    "??? would it be better to list the types of feet each word can fulfill in another column, or calculate it during search? ???\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dce504e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WORD             0\n",
       "PRONUNCIATION    0\n",
       "SYLLABLES        0\n",
       "SCANSION         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4134287a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WORD             object\n",
       "PRONUNCIATION    object\n",
       "SYLLABLES         int64\n",
       "SCANSION         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e83d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /Users/nick/opt/anaconda3/lib/python3.9/site-packages (1.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7483f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_json('words_db')\n",
    "from sqlalchemy import create_engine\n",
    "hostname='ZipCoders-MacBook-Pro.local'\n",
    "dbname='project_of_passion'\n",
    "uname='nick'\n",
    "pwd='nick123'\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\".format(host=hostname, db=dbname, user=uname,pw=pwd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa7ef4",
   "metadata": {},
   "source": [
    "Time to research how to store the database. SQL/JSON/CSV. The file is rather small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "903ec0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134316"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('words', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1acce21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
